<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>翻译:Writing_an_LLM_from_scratch_part_2 | MRZ's blog</title><meta name="author" content="MRZ"><meta name="copyright" content="MRZ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="版权声明： 除非注明，本博文章均为原创，转载请以链接形式标明本文地址。  从零开始编写大型语言模型（LLM），第二部分  ref: https:&#x2F;&#x2F;www.gilesthomas.com&#x2F;2024&#x2F;12&#x2F;llm-from-scratch-2  发布日期：2024年12月23日 分类：AI, Python, 从零开始编写LLM, TIL深度探索 我正在阅读Sebastian Raschka的书籍《">
<meta property="og:type" content="article">
<meta property="og:title" content="翻译:Writing_an_LLM_from_scratch_part_2">
<meta property="og:url" content="https://maorz.space/2025/03/09/%E7%BF%BB%E8%AF%91-Writing-an-LLM-from-scratch-part-2/index.html">
<meta property="og:site_name" content="MRZ&#39;s blog">
<meta property="og:description" content="版权声明： 除非注明，本博文章均为原创，转载请以链接形式标明本文地址。  从零开始编写大型语言模型（LLM），第二部分  ref: https:&#x2F;&#x2F;www.gilesthomas.com&#x2F;2024&#x2F;12&#x2F;llm-from-scratch-2  发布日期：2024年12月23日 分类：AI, Python, 从零开始编写LLM, TIL深度探索 我正在阅读Sebastian Raschka的书籍《">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://maorz.space/img/avatar.jpg">
<meta property="article:published_time" content="2025-03-09T13:32:04.000Z">
<meta property="article:modified_time" content="2025-03-09T13:49:26.226Z">
<meta property="article:author" content="MRZ">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://maorz.space/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://maorz.space/2025/03/09/%E7%BF%BB%E8%AF%91-Writing-an-LLM-from-scratch-part-2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><meta/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '翻译:Writing_an_LLM_from_scratch_part_2',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-03-09 21:49:26'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="MRZ's blog"><span class="site-name">MRZ's blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">翻译:Writing_an_LLM_from_scratch_part_2</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-09T13:32:04.000Z" title="发表于 2025-03-09 21:32:04">2025-03-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-03-09T13:49:26.226Z" title="更新于 2025-03-09 21:49:26">2025-03-09</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>12分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="翻译:Writing_an_LLM_from_scratch_part_2"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><hr>
<p>版权声明：<br>
除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>
<hr>
<h1>从零开始编写大型语言模型（LLM），第二部分</h1>
<blockquote>
<p>ref: <a target="_blank" rel="noopener" href="https://www.gilesthomas.com/2024/12/llm-from-scratch-2">https://www.gilesthomas.com/2024/12/llm-from-scratch-2</a></p>
</blockquote>
<p><strong>发布日期</strong>：2024年12月23日<br>
<strong>分类</strong>：AI, Python, 从零开始编写LLM, TIL深度探索</p>
<p>我正在阅读Sebastian Raschka的书籍《从零开始构建大型语言模型》，并计划每天发布阅读笔记（至少在我阅读的日子里——圣诞节那天我可能不会发布），分享我觉得有趣的内容。</p>
<p>我原本计划每天阅读一章，但对于这样一本内容密集的书来说，这个目标似乎过于乐观了！所以今天，我阅读了第二章“处理文本数据”的前半部分。这一章概述了文本在进入LLM之前的预处理过程，接着描述了一个简单的分词系统（包括源代码），然后简要介绍了我们将在LLM中实际使用的字节对编码方法。</p>
<h2 id="概述">概述</h2>
<p>核心思想是，LLM实际上无法直接处理文本——甚至无法直接处理单词。我认为，将文本输入LLM的第一步是进行分词（在我进行微调的冒险中，这一点非常常见），但事实证明，这只是第一步。</p>
<p>处理过程如下：</p>
<ol>
<li>获取原始文本，这是一系列字符（我内心的纯粹主义者想在这里说“字节”，或者添加一个初步步骤，即“确定文本使用的编码并将其转换为跨文档一致的内容”）。</li>
<li>对其进行分词，得到一系列分词ID——每个单词或子词对应一个整数。</li>
<li>为每个分词生成一个嵌入。</li>
<li>然后，这些嵌入实际上被发送到LLM。</li>
</ol>
<h2 id="词嵌入简介">词嵌入简介</h2>
<p>这里提到的嵌入是每个分词一个嵌入，而不是第一章中介绍的编码器-解码器Transformer中使用的整个句子或文档的大嵌入。但它们仍然是高维向量，以某种抽象的方式表示相关分词的含义。</p>
<p>Rashka举了Word2vec嵌入的例子，这在当时是相当轰动的，因为你可以对生成的向量进行算术运算并得到合理的结果。例如，使用w2v作为一个假想的函数，它接受一个单词并返回嵌入向量，并将+和-视为向量的逐元素运算符，我们可以看到如下内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w2v(&quot;king&quot;) - w2v(&quot;man&quot;) + w2v(&quot;woman&quot;) ~&#x3D; w2v(&quot;queen&quot;)</span><br></pre></td></tr></table></figure>
<p>或者：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w2v(&quot;Paris&quot;) - w2v(&quot;France&quot;) + w2v(&quot;Germany&quot;) ~&#x3D; w2v(&quot;Berlin&quot;)</span><br></pre></td></tr></table></figure>
<p>但更成问题的是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w2v(&quot;doctor&quot;) - w2v(&quot;man&quot;) + w2v(&quot;woman&quot;) ~&#x3D; w2v(&quot;nurse&quot;)</span><br></pre></td></tr></table></figure>
<p>这清楚地表明，保持训练材料的无偏性将非常重要。</p>
<p>无论如何，他指出，LLM使用的嵌入通常不是像Word2vec这样预先创建的，而是由与LLM本身一起训练的嵌入引擎生成的。让我感到惊讶的是，这些嵌入的维度数量——他说GPT-2有768个维度，而GPT-3则有惊人的12,288个维度！</p>
<p>他还简要提到了音频和视频的嵌入模型的存在，虽然他没有明确提到，但这让我想到了我们现在拥有的多模态LLM可能如何工作。毕竟，如果LLM只接受嵌入作为输入，那么只要它们在某种意义上是兼容的，就没有理由不让它像处理词嵌入一样处理音频嵌入或图像嵌入。不过，这只是我个人的推测。</p>
<p>在阅读这部分时，我还想到，如果LLM专门使用嵌入进行计算，那么它的直接输出可能是下一个分词的嵌入，而不是分词本身。因此，我们需要以某种方式从嵌入映射到分词，这将非常困难（在数千维的空间中找到与随机嵌入最接近的分词是一项昂贵的操作），所以也许这种对称性“嵌入 -&gt; LLM -&gt; 嵌入”只是我的一个误解，LLM实际上只是生成下一个分词（或者更准确地说，是一组带有相关概率的分词）。我们拭目以待！</p>
<h2 id="分词：自己编写">分词：自己编写</h2>
<p>这部分对我来说没有太多新内容——分词的概念，即将单词（或部分单词）转换为数字，我认为任何阅读本文的人都会熟悉，而Raschka所实现的代码非常简单明了。</p>
<p>在第一个版本中，我们将文本拆分为单词和标点符号，例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;Hello, how are you?&quot; -&gt; [&quot;Hello&quot;, &quot;,&quot;, &quot;how&quot;, &quot;are&quot;, &quot;you&quot;, &quot;?&quot;]</span><br></pre></td></tr></table></figure>
<p>（他指出，如果需要，可以保留空格，例如Python代码。）</p>
<p>完成此操作后，为每个唯一的单词/标点符号分配一个唯一的整数，并构建一个从单词到ID的映射。</p>
<p>有了这个映射，你可以构建一个简单的类，其中包含一个<code>encode</code>方法，将文本映射到分词ID列表，以及一个<code>decode</code>方法，将此类列表转换回文本。</p>
<p>然而，如果它遇到一个从未见过的单词，它将会中断。因此，在第二个版本中，我们增强了它以处理未知单词。他通过在生成单词到ID映射之前将字符串<code>&lt;|unk|&gt;</code>添加到词汇表中来实现这一点，这样它就会获得一个ID，然后修改编码器，以便在遇到不认识的单词时输出该分词。他还添加了一个<code>&lt;|endoftext|&gt;</code>分词，以便在同一输入流中分隔不同的文档。</p>
<p>这是一个很好的解决方案，效果很好，但我从之前的阅读中得到的印象是，这并不是当前的最佳实践（例如，截至GPT-4）。我想这里使用的系统是因为Raschka在这段代码中试图实现的只是一个分词工作原理的示例——也就是说，这段代码是一个用于教学目的的简单实现。</p>
<p>但无论如何，我会解释我认为它的问题所在，主要是为了确保我真正理解它 :-)</p>
<p>如果<code>&lt;|endoftext|&gt;</code>出现在一个简单的从单词到分词ID的编码器的词汇表中，那么有人可以将该字符串放入LLM应用程序的提示中，并获得该分词。我相当确定我记得一些早期的提示注入/越狱技巧，这些技巧似乎就是沿着这些思路工作的。</p>
<p>有一些方法可以避免这种情况（参见下一节中的好例子），但它给人一种感觉，即那些足够擅长越狱的人可能能够绕过它。当我看到它时，我脑海中负责在网站代码中触发SQL注入警报的部分确实被触发了。</p>
<p>根据我的了解（我可能完全错了），最新的分词器没有任何特定字符串映射到特殊分词——也就是说，它们只是分词ID。在解码方法中可能会有一些输出它们的方式，但在编码方法中无法通过使用特殊格式的文本来生成它们。因此，例如，生成保留给未知单词的分词ID的唯一方法是提供一个未知单词。</p>
<p>无论如何，所有这些都无关紧要，因为我们将用于LLM本身的分词器不是上面的那个，而是更复杂的东西。</p>
<h2 id="分词：字节对编码">分词：字节对编码</h2>
<p>使用具有固定词汇表的分词器（如上所述）的问题是：</p>
<ol>
<li>你最终不得不扫描整个训练集以找到所有唯一的单词（如果你在训练整个互联网的抓取数据，你会发现各种各样的东西，比如<code>lksfdklkajfdfklj</code>）。你会得到一个包含大量几乎从未使用过的单词的庞大词汇表，然而，在训练之后，你仍然会遇到包含训练中未见过的单词的输入问题。</li>
<li>或者你只是接受在训练期间也会出现未知单词，这限制了你的LLM可以学习的内容。</li>
</ol>
<p>我们可以通过更复杂的分词器来避免这个问题。Rashka提供了一些使用OpenAI的<code>tiktoken</code>库的示例代码，该库使用字节对编码进行分词。字节对编码是一种系统，分词器通过训练过程学习自己的分词集——即：</p>
<ol>
<li>它最初拥有所有字母、数字和标点符号的分词。</li>
<li>然后它被展示大量数据，发现现有分词的常见组合，并为它们创建新的分词。</li>
<li>未知单词可以由它拥有的分词表示——在最坏的情况下，它只需要逐个字母拼写出来。</li>
</ol>
<p>他展示的示例代码给出了一个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">64</span>]: <span class="keyword">import</span> tiktoken</span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: tokenizer = tiktoken.get_encoding(<span class="string">&quot;gpt2&quot;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">66</span>]: text = <span class="string">&quot;Hello, do you like tea? &lt;|endoftext|&gt; In the sunlit terraces of someunknownPlace.&quot;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: integers = tokenizer.encode(text, allowed_special=&#123;<span class="string">&quot;&lt;|endoftext|&gt;&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">68</span>]: tokenizer.decode(integers)</span><br><span class="line">Out[<span class="number">68</span>]: <span class="string">&#x27;Hello, do you like tea? &lt;|endoftext|&gt; In the sunlit terraces of someunknownPlace.&#x27;</span></span><br><span class="line">In [<span class="number">69</span>]: [tokenizer.decode([ii]) <span class="keyword">for</span> ii <span class="keyword">in</span> integers]</span><br><span class="line">Out[<span class="number">69</span>]:</span><br><span class="line">[<span class="string">&#x27;Hello&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;,&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27; do&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27; you&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27; like&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27; tea&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;?&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27; &#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;&lt;|endoftext|&gt;&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27; In&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27; the&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27; sun&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;lit&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27; terr&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;aces&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27; of&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27; some&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;unknown&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Place&#x27;</span>,</span><br></pre></td></tr></table></figure>
<p>所以你可以看到&quot;someunknownPlace&quot;被分解为&quot;some&quot;、&quot;unknown&quot;和&quot;Place&quot;的分词。</p>
<p>这也突出了我之前从其他地方了解到的一点——现代分词器通常将前导空格作为分词本身的一部分，因此——例如——&quot; do&quot;和&quot;do&quot;有不同的分词——它们有不同的ID：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">70</span>]: print(tokenizer.encode(<span class="string">&quot;do do&quot;</span>))</span><br><span class="line">[<span class="number">4598</span>, <span class="number">466</span>]</span><br></pre></td></tr></table></figure>
<p>解码后看起来也不同：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">71</span>]: [tokenizer.decode([ii]) <span class="keyword">for</span> ii <span class="keyword">in</span> tokenizer.encode(<span class="string">&quot;do do&quot;</span>)]</span><br><span class="line">Out[<span class="number">71</span>]: [<span class="string">&#x27;do&#x27;</span>, <span class="string">&#x27; do&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>另一个让我感兴趣的是encode调用中的allowed_special参数，这是一种预防措施，以防止我之前提到的越狱问题。有了它，它将愉快地将文本解析为特殊分词：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">72</span>]: [tokenizer.decode([ii]) <span class="keyword">for</span> ii <span class="keyword">in</span> tokenizer.encode(<span class="string">&quot;&lt;|endoftext|&gt;&quot;</span>, allowed_special=&#123;<span class="string">&quot;&lt;|endoftext|&gt;&quot;</span>&#125;)]</span><br><span class="line">Out[<span class="number">72</span>]: [<span class="string">&#x27;&lt;|endoftext|&gt;&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>没有它，分词器会识别并拒绝它：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">73</span>]: [tokenizer.decode([ii]) <span class="keyword">for</span> ii <span class="keyword">in</span> tokenizer.encode(<span class="string">&quot;&lt;|endoftext|&gt;&quot;</span>)]</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">ValueError                                Traceback (most recent call last)</span><br><span class="line">Cell In[<span class="number">73</span>], line <span class="number">1</span></span><br><span class="line">----&gt; 1 [tokenizer.decode([ii]) for ii in tokenizer.encode(&quot;&lt;|endoftext|&gt;&quot;)]</span><br><span class="line"></span><br><span class="line">File ~/.virtualenvs/llm-<span class="keyword">from</span>-scratch/lib/python3<span class="number">.12</span>/site-packages/tiktoken/core.py:<span class="number">117</span>, <span class="keyword">in</span> Encoding.encode(self, text, allowed_special, disallowed_special)</span><br><span class="line">    <span class="number">115</span>         disallowed_special = <span class="built_in">frozenset</span>(disallowed_special)</span><br><span class="line">    <span class="number">116</span>     <span class="keyword">if</span> match := _special_token_regex(disallowed_special).search(text):</span><br><span class="line">--&gt; 117         raise_disallowed_special_token(match.group())</span><br><span class="line">    <span class="number">119</span> <span class="keyword">try</span>:</span><br><span class="line">    <span class="number">120</span>     <span class="keyword">return</span> self._core_bpe.encode(text, allowed_special)</span><br><span class="line"></span><br><span class="line">File ~/.virtualenvs/llm-<span class="keyword">from</span>-scratch/lib/python3<span class="number">.12</span>/site-packages/tiktoken/core.py:<span class="number">398</span>, <span class="keyword">in</span> raise_disallowed_special_token(token)</span><br><span class="line">    <span class="number">397</span> <span class="function"><span class="keyword">def</span> <span class="title">raise_disallowed_special_token</span>(<span class="params">token: <span class="built_in">str</span></span>) -&gt; NoReturn:</span></span><br><span class="line">--&gt; 398     raise ValueError(</span><br><span class="line">    <span class="number">399</span>         <span class="string">f&quot;Encountered text corresponding to disallowed special token <span class="subst">&#123;token!r&#125;</span>.\n&quot;</span></span><br><span class="line">    <span class="number">400</span>         <span class="string">&quot;If you want this text to be encoded as a special token, &quot;</span></span><br><span class="line">    <span class="number">401</span>         <span class="string">f&quot;pass it to &lt;!--CODE_BLOCK_4958--&gt;, e.g. &lt;!--CODE_BLOCK_4959--&gt;.\n&quot;</span></span><br><span class="line">    <span class="number">402</span>         <span class="string">f&quot;If you want this text to be encoded as normal text, disable the check for this token &quot;</span></span><br><span class="line">    <span class="number">403</span>         <span class="string">f&quot;by passing &lt;!--CODE_BLOCK_4960--&gt;.\n&quot;</span></span><br><span class="line">    <span class="number">404</span>         <span class="string">&quot;To disable this check for all special tokens, pass &lt;!--CODE_BLOCK_4961--&gt;.\n&quot;</span></span><br><span class="line">    <span class="number">405</span>     )</span><br><span class="line"></span><br><span class="line">ValueError: Encountered text corresponding to disallowed special token <span class="string">&#x27;&lt;|endoftext|&gt;&#x27;</span>.</span><br><span class="line">If you want this text to be encoded as a special token, pass it to &lt;!--CODE_BLOCK_4962--&gt;, e.g. &lt;!--CODE_BLOCK_4963--&gt;.</span><br><span class="line">If you want this text to be encoded as normal text, disable the check for this token by passing &lt;!--CODE_BLOCK_4964--&gt;.</span><br><span class="line">To disable this check for all special tokens, pass &lt;!--CODE_BLOCK_4965--&gt;.</span><br></pre></td></tr></table></figure>
<p>或者，根据那个（非常详细的）错误消息，你可以让它被解析为没有任何特殊含义的字符序列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">77</span>]: [tokenizer.decode([ii]) <span class="keyword">for</span> ii <span class="keyword">in</span> tokenizer.encode(<span class="string">&quot;&lt;|endoftext|&gt;&quot;</span>, disallowed_special=(tokenizer.special_tokens_set - &#123;<span class="string">&#x27;&lt;|endoftext|&gt;&#x27;</span>&#125;))]</span><br><span class="line">Out[<span class="number">77</span>]: [<span class="string">&#x27;&lt;&#x27;</span>, <span class="string">&#x27;|&#x27;</span>, <span class="string">&#x27;end&#x27;</span>, <span class="string">&#x27;of&#x27;</span>, <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;|&#x27;</span>, <span class="string">&#x27;&gt;&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>最后一个感觉有点冒险！在一个更大的系统中（比如某种LLM相互通信的框架），很容易想象这些分词流被天真的代码重新组装，然后像受信任的一样进行分词。</p>
<h2 id="总结">总结</h2>
<p>无论如何，我觉得今天就到这里吧。有趣的是，我觉得我花在整理这些笔记上的时间大约是阅读时间的两倍，但这可能是一个很好的平衡。我确信，通过这次写作，我会更好地记住我读到的内容！</p>
<p>接下来的部分，我预计明天会阅读（尽管是平安夜，所以我可能无法完成），是关于数据采样的，然后是创建嵌入。我原本以为后者会非常复杂，但在快速浏览后，我发现我们在现阶段所做的只是生成随机嵌入，这是有道理的——实际值将在我们开始训练时学习。</p>
<h2 id="小问题和奇怪之处">小问题和奇怪之处</h2>
<p>今天只有一个问题——真的是我在吹毛求疵，但在第28页，命令<code>print(tokenizer.decode(ids))</code>的输出被渲染为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#39;&quot; It\&#39; s the last to be painted, you know,&quot; Mrs. Gisburn said with pardonable pride.&#39;</span><br></pre></td></tr></table></figure>
<p>它应该是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot; It&#39; s the last to be painted, you know,&quot; Mrs. Gisburn said with pardonable pride.</span><br></pre></td></tr></table></figure>
<p>——我猜它是从CLI会话中复制粘贴的，其中命令只是<code>tokenizer.decode(ids)</code>，所以Python提供了一个<code>repr</code>。</p>
<p>基本上是一个错别字，我觉得甚至提到它都有点不好意思 ;-)</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://maorz.space">MRZ</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://maorz.space/2025/03/09/%E7%BF%BB%E8%AF%91-Writing-an-LLM-from-scratch-part-2/">https://maorz.space/2025/03/09/%E7%BF%BB%E8%AF%91-Writing-an-LLM-from-scratch-part-2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://maorz.space" target="_blank">MRZ's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2025/03/09/%E7%BF%BB%E8%AF%91-Writing-an-LLM-from-scratch-part-1/" title="翻译:Writing_an_LLM_from_scratch_part_1"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">翻译:Writing_an_LLM_from_scratch_part_1</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">MRZ</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/godjos" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到MRZ的博客,欢迎大家分享和交流.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">从零开始编写大型语言模型（LLM），第二部分</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%8D%E5%B5%8C%E5%85%A5%E7%AE%80%E4%BB%8B"><span class="toc-text">词嵌入简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E8%AF%8D%EF%BC%9A%E8%87%AA%E5%B7%B1%E7%BC%96%E5%86%99"><span class="toc-text">分词：自己编写</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E8%AF%8D%EF%BC%9A%E5%AD%97%E8%8A%82%E5%AF%B9%E7%BC%96%E7%A0%81"><span class="toc-text">分词：字节对编码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E9%97%AE%E9%A2%98%E5%92%8C%E5%A5%87%E6%80%AA%E4%B9%8B%E5%A4%84"><span class="toc-text">小问题和奇怪之处</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/09/%E7%BF%BB%E8%AF%91-Writing-an-LLM-from-scratch-part-2/" title="翻译:Writing_an_LLM_from_scratch_part_2">翻译:Writing_an_LLM_from_scratch_part_2</a><time datetime="2025-03-09T13:32:04.000Z" title="发表于 2025-03-09 21:32:04">2025-03-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/09/%E7%BF%BB%E8%AF%91-Writing-an-LLM-from-scratch-part-1/" title="翻译:Writing_an_LLM_from_scratch_part_1">翻译:Writing_an_LLM_from_scratch_part_1</a><time datetime="2025-03-09T12:56:57.000Z" title="发表于 2025-03-09 20:56:57">2025-03-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/04/%E4%B8%8E%E6%80%A7%E8%83%BD%E7%9B%B8%E5%85%B3%E7%9A%84%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E6%96%87%E7%8C%AE/" title="与性能相关的矩阵特征文献"><img src="https://s2.loli.net/2024/06/04/AMqryoJX7SQ93gm.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="与性能相关的矩阵特征文献"/></a><div class="content"><a class="title" href="/2024/06/04/%E4%B8%8E%E6%80%A7%E8%83%BD%E7%9B%B8%E5%85%B3%E7%9A%84%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E6%96%87%E7%8C%AE/" title="与性能相关的矩阵特征文献">与性能相关的矩阵特征文献</a><time datetime="2024-06-04T12:59:15.000Z" title="发表于 2024-06-04 20:59:15">2024-06-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/31/AMG%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/" title="AMG性能优化相关文章"><img src="https://s2.loli.net/2023/03/31/B8k1udiy75PSjr6.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AMG性能优化相关文章"/></a><div class="content"><a class="title" href="/2023/03/31/AMG%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/" title="AMG性能优化相关文章">AMG性能优化相关文章</a><time datetime="2023-03-31T11:51:44.000Z" title="发表于 2023-03-31 19:51:44">2023-03-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/09/HPCToolKit%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/" title="HPCToolKit基础使用教程"><img src="https://s2.loli.net/2023/02/09/KnQ17ctEd3MX2iV.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HPCToolKit基础使用教程"/></a><div class="content"><a class="title" href="/2023/02/09/HPCToolKit%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/" title="HPCToolKit基础使用教程">HPCToolKit基础使用教程</a><time datetime="2023-02-09T06:48:44.000Z" title="发表于 2023-02-09 14:48:44">2023-02-09</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By MRZ</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://maorz.space/2025/03/09/%E7%BF%BB%E8%AF%91-Writing-an-LLM-from-scratch-part-2/'
    this.page.identifier = '/2025/03/09/%E7%BF%BB%E8%AF%91-Writing-an-LLM-from-scratch-part-2/'
    this.page.title = '翻译:Writing_an_LLM_from_scratch_part_2'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://godjosblog.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }

  document.getElementById('darkmode').addEventListener('click', () => {
    setTimeout(() => window.disqusReset(), 200)
  })
}

if ('Disqus' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>